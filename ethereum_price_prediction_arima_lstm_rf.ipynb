{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Ethereum Price Prediction with ARIMA, LSTM and Random Forest\n", "\n", "This notebook downloads daily ETH-USD prices and compares three models:\n", "\n", "- ARIMA (classical time series)\n", "- LSTM (deep learning)\n", "- Random Forest (tree-based machine learning)\n", "\n", "You can run this end-to-end on Google Colab or a local Jupyter environment.\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# If you run this on a fresh environment (e.g. Colab),\n", "# uncomment the line below to install the required packages.\n", "\n", "# !pip install yfinance statsmodels tensorflow scikit-learn\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "\n", "from sklearn.metrics import mean_squared_error, mean_absolute_error\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.preprocessing import MinMaxScaler\n", "\n", "import yfinance as yf\n", "from statsmodels.tsa.arima.model import ARIMA\n", "\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import LSTM, Dense\n", "from tensorflow.keras.callbacks import EarlyStopping\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def evaluate_regression(y_true, y_pred, name=\"model\"):\n", "    mse = mean_squared_error(y_true, y_pred)\n", "    rmse = np.sqrt(mse)\n", "    mae = mean_absolute_error(y_true, y_pred)\n", "    print(f\"{name} -> RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n", "    return {\"name\": name, \"rmse\": rmse, \"mae\": mae}\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["symbol = \"ETH-USD\"\n", "start_date = \"2017-01-01\"\n", "\n", "eth_df = yf.download(symbol, start=start_date)\n", "eth_df = eth_df[[\"Close\"]].dropna()\n", "print(eth_df.head())\n", "print(eth_df.tail())\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["plt.figure(figsize=(10, 4))\n", "plt.plot(eth_df[\"Close\"])\n", "plt.title(\"ETH-USD Closing Price\")\n", "plt.xlabel(\"Date\")\n", "plt.ylabel(\"Price (USD)\")\n", "plt.tight_layout()\n", "plt.show()\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["train_size = int(len(eth_df) * 0.8)\n", "train_arima = eth_df[\"Close\"].iloc[:train_size]\n", "test_arima = eth_df[\"Close\"].iloc[train_size:]\n", "\n", "print(f\"Train points: {len(train_arima)}, Test points: {len(test_arima)}\")\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# === ARIMA model ===\n", "p, d, q = 5, 1, 0  # you can tune these manually later\n", "\n", "arima_model = ARIMA(train_arima, order=(p, d, q))\n", "arima_result = arima_model.fit()\n", "\n", "print(arima_result.summary())\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["arima_forecast = arima_result.forecast(steps=len(test_arima))\n", "arima_forecast.index = test_arima.index  # align index\n", "\n", "metrics_arima = evaluate_regression(test_arima.values, arima_forecast.values, name=\"ARIMA\")\n", "\n", "plt.figure(figsize=(10, 4))\n", "plt.plot(train_arima.index, train_arima.values, label=\"Train\")\n", "plt.plot(test_arima.index, test_arima.values, label=\"Test\")\n", "plt.plot(arima_forecast.index, arima_forecast.values, label=\"ARIMA forecast\")\n", "plt.title(\"ARIMA - ETH-USD Close Price Forecast\")\n", "plt.xlabel(\"Date\")\n", "plt.ylabel(\"Price (USD)\")\n", "plt.legend()\n", "plt.tight_layout()\n", "plt.show()\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# === Shared preparation for LSTM and Random Forest ===\n", "\n", "values = eth_df[\"Close\"].values.reshape(-1, 1)\n", "\n", "scaler = MinMaxScaler()\n", "values_scaled = scaler.fit_transform(values)\n", "\n", "def create_sequences(series, window_size=60):\n", "    X, y = [], []\n", "    for i in range(len(series) - window_size):\n", "        X.append(series[i : i + window_size])\n", "        y.append(series[i + window_size])\n", "    return np.array(X), np.array(y)\n", "\n", "window_size = 60\n", "X_all, y_all = create_sequences(values_scaled, window_size=window_size)\n", "\n", "print(\"X_all shape:\", X_all.shape, \"y_all shape:\", y_all.shape)\n", "\n", "# Train / test split on the sequences\n", "train_size_seq = int(len(X_all) * 0.8)\n", "\n", "X_train_seq = X_all[:train_size_seq]\n", "y_train_seq = y_all[:train_size_seq]\n", "\n", "X_test_seq = X_all[train_size_seq:]\n", "y_test_seq = y_all[train_size_seq:]\n", "\n", "print(\"Train sequences:\", X_train_seq.shape, \"Test sequences:\", X_test_seq.shape)\n", "\n", "# Date index for y values\n", "dates_all = eth_df.index[window_size:]\n", "train_dates_seq = dates_all[:train_size_seq]\n", "test_dates_seq = dates_all[train_size_seq:]\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# === LSTM model ===\n", "\n", "X_train_lstm = X_train_seq\n", "X_test_lstm = X_test_seq\n", "\n", "model_lstm = Sequential([\n", "    LSTM(50, input_shape=(window_size, 1)),\n", "    Dense(1)\n", "])\n", "\n", "model_lstm.compile(optimizer=\"adam\", loss=\"mse\")\n", "\n", "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n", "\n", "history = model_lstm.fit(\n", "    X_train_lstm,\n", "    y_train_seq,\n", "    epochs=50,\n", "    batch_size=32,\n", "    validation_split=0.2,\n", "    callbacks=[early_stop],\n", "    verbose=1,\n", ")\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["lstm_pred_scaled = model_lstm.predict(X_test_lstm)\n", "y_test_lstm_scaled = y_test_seq.reshape(-1, 1)\n", "\n", "lstm_pred = scaler.inverse_transform(lstm_pred_scaled)\n", "y_test_lstm = scaler.inverse_transform(y_test_lstm_scaled)\n", "\n", "metrics_lstm = evaluate_regression(y_test_lstm.ravel(), lstm_pred.ravel(), name=\"LSTM\")\n", "\n", "plt.figure(figsize=(10, 4))\n", "plt.plot(test_dates_seq, y_test_lstm.ravel(), label=\"True\")\n", "plt.plot(test_dates_seq, lstm_pred.ravel(), label=\"LSTM prediction\")\n", "plt.title(\"LSTM - ETH-USD Close Price Forecast\")\n", "plt.xlabel(\"Date\")\n", "plt.ylabel(\"Price (USD)\")\n", "plt.legend()\n", "plt.tight_layout()\n", "plt.show()\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# === Random Forest model ===\n", "\n", "# Flatten the time dimension into features\n", "X_train_rf = X_train_seq.reshape(X_train_seq.shape[0], -1)\n", "X_test_rf = X_test_seq.reshape(X_test_seq.shape[0], -1)\n", "\n", "rf = RandomForestRegressor(\n", "    n_estimators=300,\n", "    max_depth=None,\n", "    random_state=42,\n", "    n_jobs=-1\n", ")\n", "\n", "rf.fit(X_train_rf, y_train_seq.ravel())\n", "\n", "rf_pred_scaled = rf.predict(X_test_rf).reshape(-1, 1)\n", "y_test_rf_scaled = y_test_seq.reshape(-1, 1)\n", "\n", "rf_pred = scaler.inverse_transform(rf_pred_scaled)\n", "y_test_rf = scaler.inverse_transform(y_test_rf_scaled)\n", "\n", "metrics_rf = evaluate_regression(y_test_rf.ravel(), rf_pred.ravel(), name=\"Random Forest\")\n", "\n", "plt.figure(figsize=(10, 4))\n", "plt.plot(test_dates_seq, y_test_rf.ravel(), label=\"True\")\n", "plt.plot(test_dates_seq, rf_pred.ravel(), label=\"RF prediction\")\n", "plt.title(\"Random Forest - ETH-USD Close Price Forecast\")\n", "plt.xlabel(\"Date\")\n", "plt.ylabel(\"Price (USD)\")\n", "plt.legend()\n", "plt.tight_layout()\n", "plt.show()\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["summary = pd.DataFrame([\n", "    metrics_arima,\n", "    metrics_lstm,\n", "    metrics_rf\n", "]).set_index(\"name\")\n", "summary\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}